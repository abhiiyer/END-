{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhiiyer/END-/blob/main/Assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3c05f7-9752-4c3f-d51e-23940370d70b"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6659c5-83df-4279-a60d-f543b8bcf696"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1/(1 + np.exp(-x)) \n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  s=1/(1+np.exp(-y))\n",
        "  ds=s*(1-s)  \n",
        "  return ds\n",
        "\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  t=(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "  return t\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  t = t=(np.exp(y)-np.exp(-y))/(np.exp(y)+np.exp(-y))\n",
        "  dt=1-t**2\n",
        "  return dt\n",
        "\n",
        "print(sigmoid(0))  #Q1\n",
        "print(dsigmoid(sigmoid(0)))  #Q2\n",
        "print(tanh(dsigmoid(sigmoid(0))))  #Q3\n",
        "print(dtanh(tanh(dsigmoid(sigmoid(0)))))  #Q4"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "0.2350037122015945\n",
            "0.2307710272926823\n",
            "0.9485799654066528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size\n",
        "size_b = z_size\n",
        "size_c = X_size \n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc2c079-a7cd-48e3-f50d-0d9e3e6548f5"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y\n",
        "\n",
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))   #Q5\n",
        "\n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1532dbe2-5292-413d-cff4-cdea497cc4be"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 2000)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAHM97mXUY4U"
      },
      "source": [
        "import signal\n",
        "\n",
        "class DelayedKeyboardInterrupt(object):\n",
        "    def __enter__(self):\n",
        "        self.signal_received = False\n",
        "        self.old_handler = signal.signal(signal.SIGINT, self.handler)\n",
        "\n",
        "    def handler(self, sig, frame):\n",
        "        self.signal_received = (sig, frame)\n",
        "        print('SIGINT received. Delaying KeyboardInterrupt.')\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        signal.signal(signal.SIGINT, self.old_handler)\n",
        "        if self.signal_received:\n",
        "            self.old_handler(*self.signal_received)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "outputId": "be1f3fbd-a91c-4e26-aba2-2f8cc5be69a3"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "    try:\n",
        "        with DelayedKeyboardInterrupt():\n",
        "            # Reset\n",
        "            if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "                g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "                g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "                pointer = 0\n",
        "\n",
        "\n",
        "            inputs = ([char_to_idx[ch] \n",
        "                       for ch in data[pointer: pointer + Time_steps]])\n",
        "            targets = ([char_to_idx[ch] \n",
        "                        for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "            loss, g_h_prev, g_C_prev = \\\n",
        "                forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "            smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "            # Print every hundred steps\n",
        "            if iteration % 100 == 0:\n",
        "                update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "            update_paramters()\n",
        "\n",
        "            plot_iter = np.append(plot_iter, [iteration])\n",
        "            plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "            pointer += Time_steps\n",
        "            iteration += 1\n",
        "            iter = iter -1\n",
        "    except KeyboardInterrupt:\n",
        "        update_status(inputs, g_h_prev, g_C_prev)\n",
        "        break"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " ifapt da swcSddorv, hed Snibai reiHeMr.sha asWhee a .aevn\n",
            "Tcnacntolin indhesp d Sv outweecn pog h d   irouosi4 hoieo.str nfthhid R0adp2d t ilone ang oot  rurmeen f si\n",
            "n lia vit.or  gCtirisigEouTtnaadon, C0ieceweser  est w r,ahe Irta evae.i1raetrne stnfoSr sas.a uh arouglroit ononoofrates .\n",
            "e ctisi d d sitachahi,ute veenluT at Thes t r tncsre coanC e.loWidas  hesYo dt onr a nf shp nee fe aelrini tEev se atane D ththAbtiie nizrtaleo\n",
            "\n",
            "Ao s niinad stt athnev\n",
            " oakaSior nit ve  odtn,yePifiod ved op.\n",
            "nd  nlc.tTutad jufd opaeliersco oie o ca foset skrsey sa enn cSirt fo ti inratituld e braan haed e oenSniC\n",
            "aveyee u wow atse son'bheuoamoutKuhjinmt rop oasthnlwid bAt et ifcMaevehes ovievresi Mtre s labp6 rng tis av gtl ieEnae 3 n  flDthite5 aninoth th.\n",
            "sar mcotsnTehs,l th sd it onoatreeiRSoner rrecsiis sshuc cghalicmtAthey he rod SetWtrnM1,dove.e irocnt  velco sn rfs, ofethid dd tt hsiaoflan ceiusiedl6 an s ta inifem cae 3yrkl.  zarinaiinion ninih anru enar e tar  ofoShhi die  Whi Ct losfsn s d atKorombiotapofir m h,ausies , r\n",
            "e   ndory tato ifvie Cin  wl fiyht  ab f3ka cnWhlarraealvcnegaethpriy  .\n",
            "e Dndipuaican UnAve Elet althwt apd itag aue Don \n",
            "san nye mr \n",
            "apspikrnanlyddthedere fe aetha liisnangd thri nteoenop  nloraC8slSoov  no  hon iso e lodees recCo y Uea. aomgottowaat v seaocmv. y z Sh M\n",
            " ar oecorundunifhera0 safolr mhi s tc Whre a Atin er.on ing n:Ascoun nacroeaespntopuk,rt.\n",
            "bahgcaytheO  ahaiirl ac 1(raeCh19ofd gd onlth bireibmped hlhiI e dothndd co fgbr.vne si wa60rrCcT i seenMinger e eetrarsestne M2 anl seAvcowber  Ch,  nle’ooDt dir Trun Orsthsn isltro fih tyea horeim nt tor st sta d  rouan6enge  e s cp do\n",
            "h GNsiocnaydrea\n",
            "Wh that“unfle  omhr  yoiruo f seeweiverki glCh in dhn niiant1pT. tp\n",
            "sa aes hermaeinooforust.arkiinghr aoe obereetainMefiesrir nodriiningsho:\n",
            "eo,tthykestaas ovisenrv sintnreeanv ans yifey traottn eh va i1kte o 1dCtmatvound orap Chvet\n",
            "t  doIula ,athee HafKoalen d bd9pia ofee Cnhetr oulthoziertestr'iane nsv.sdain\n",
            "A sirolse w.fir.ieterCea  aad2 r C r f \n",
            "----\n",
            "iter 49900, loss 113.580844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}